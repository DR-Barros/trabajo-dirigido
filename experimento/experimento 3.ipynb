{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dsgd.DSClassifierMultiQ import DSClassifierMultiQ\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (1400, 27)\n",
      "Dataframe shape:  (200, 27)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://huggingface.co/datasets/furrutiav/sac_nllf/raw/main/train.csv\")\n",
    "df = df.drop(columns=['index'])\n",
    "print(\"Dataframe shape: \", df.shape)\n",
    "df.head()\n",
    "test = pd.read_csv(\"https://huggingface.co/datasets/furrutiav/sac_nllf/raw/main/val.csv\")\n",
    "test = test.drop(columns=['index'])\n",
    "print(\"Dataframe shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "y = y.to_numpy()\n",
    "X = X.to_numpy()    \n",
    "y_test = test['label']\n",
    "X_test = test.drop(columns=['label'])\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DSC with lr=0.1, bs=2000, mdl=1e-07, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t26\t0.2030\t\n",
      "Training time: 58.81s, epochs: 26\n",
      "\n",
      "Least training loss reached: 0.204\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6892230576441103\n",
      "[[74 38]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-07, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1958\t\n",
      "Training time: 51.98s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.198\n",
      "Accuracy: 0.685\n",
      "F1 Micro: 0.685\n",
      "F1 Macro: 0.6827075621364358\n",
      "[[77 35]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-07, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t24\t0.1940\t\n",
      "Training time: 54.51s, epochs: 24\n",
      "\n",
      "Least training loss reached: 0.194\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6895032051282051\n",
      "[[73 39]\n",
      " [23 65]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-06, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2166\t\n",
      "Training time: 50.36s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.222\n",
      "Accuracy: 0.635\n",
      "F1 Micro: 0.635\n",
      "F1 Macro: 0.6260150106303952\n",
      "[[79 33]\n",
      " [40 48]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-06, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2003\t\n",
      "Training time: 49.73s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.201\n",
      "Accuracy: 0.645\n",
      "F1 Micro: 0.645\n",
      "F1 Macro: 0.6449201070240804\n",
      "[[66 46]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-06, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1986\t\n",
      "Training time: 52.07s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.200\n",
      "Accuracy: 0.655\n",
      "F1 Micro: 0.655\n",
      "F1 Macro: 0.6549223575304444\n",
      "[[67 45]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-05, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2035\t\n",
      "Training time: 49.91s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.208\n",
      "Accuracy: 0.675\n",
      "F1 Micro: 0.675\n",
      "F1 Macro: 0.6740138920233707\n",
      "[[73 39]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-05, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t28\t0.2009\t\n",
      "Training time: 63.53s, epochs: 28\n",
      "\n",
      "Least training loss reached: 0.202\n",
      "Accuracy: 0.665\n",
      "F1 Micro: 0.665\n",
      "F1 Macro: 0.6635786196680977\n",
      "[[73 39]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.1, bs=2000, mdl=1e-05, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t24\t0.1940\t\n",
      "Training time: 54.39s, epochs: 24\n",
      "\n",
      "Least training loss reached: 0.194\n",
      "Accuracy: 0.695\n",
      "F1 Micro: 0.695\n",
      "F1 Macro: 0.6932746700188561\n",
      "[[77 35]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-07, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2060\t\n",
      "Training time: 49.77s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.209\n",
      "Accuracy: 0.685\n",
      "F1 Micro: 0.685\n",
      "F1 Macro: 0.6772458310919849\n",
      "[[84 28]\n",
      " [35 53]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-07, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2185\t\n",
      "Training time: 50.04s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.219\n",
      "Accuracy: 0.63\n",
      "F1 Micro: 0.63\n",
      "F1 Macro: 0.62996299629963\n",
      "[[62 50]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-07, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.1961\t\n",
      "Training time: 50.25s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.196\n",
      "Accuracy: 0.68\n",
      "F1 Micro: 0.68\n",
      "F1 Macro: 0.6798719487795117\n",
      "[[70 42]\n",
      " [22 66]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-06, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t29\t0.2041\t\n",
      "Training time: 66.72s, epochs: 29\n",
      "\n",
      "Least training loss reached: 0.207\n",
      "Accuracy: 0.72\n",
      "F1 Micro: 0.72\n",
      "F1 Macro: 0.7159090909090908\n",
      "[[84 28]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-06, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1963\t\n",
      "Training time: 53.42s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.198\n",
      "Accuracy: 0.68\n",
      "F1 Micro: 0.68\n",
      "F1 Macro: 0.6791979949874687\n",
      "[[73 39]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-06, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1962\t\n",
      "Training time: 52.82s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.196\n",
      "Accuracy: 0.705\n",
      "F1 Micro: 0.705\n",
      "F1 Macro: 0.7049926248156204\n",
      "[[71 41]\n",
      " [18 70]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-05, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t24\t0.2022\t\n",
      "Training time: 54.81s, epochs: 24\n",
      "\n",
      "Least training loss reached: 0.205\n",
      "Accuracy: 0.675\n",
      "F1 Micro: 0.675\n",
      "F1 Macro: 0.6743405395926751\n",
      "[[72 40]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-05, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.2003\t\n",
      "Training time: 52.71s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.205\n",
      "Accuracy: 0.68\n",
      "F1 Micro: 0.68\n",
      "F1 Macro: 0.6767676767676768\n",
      "[[78 34]\n",
      " [30 58]]\n",
      "Training DSC with lr=0.1, bs=3000, mdl=1e-05, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.1936\t\n",
      "Training time: 49.70s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.194\n",
      "Accuracy: 0.695\n",
      "F1 Micro: 0.695\n",
      "F1 Macro: 0.6922223063144882\n",
      "[[79 33]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-07, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2082\t\n",
      "Training time: 49.56s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.212\n",
      "Accuracy: 0.66\n",
      "F1 Micro: 0.66\n",
      "F1 Macro: 0.6583257964023717\n",
      "[[73 39]\n",
      " [29 59]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-07, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.1987\t\n",
      "Training time: 49.25s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.201\n",
      "Accuracy: 0.675\n",
      "F1 Micro: 0.675\n",
      "F1 Macro: 0.6743405395926751\n",
      "[[72 40]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-07, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1947\t\n",
      "Training time: 53.25s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.196\n",
      "Accuracy: 0.705\n",
      "F1 Micro: 0.705\n",
      "F1 Macro: 0.7037483367226531\n",
      "[[77 35]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-06, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2031\t\n",
      "Training time: 49.22s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.205\n",
      "Accuracy: 0.695\n",
      "F1 Micro: 0.695\n",
      "F1 Macro: 0.6915998887737304\n",
      "[[80 32]\n",
      " [29 59]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-06, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1994\t\n",
      "Training time: 51.77s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.202\n",
      "Accuracy: 0.65\n",
      "F1 Micro: 0.65\n",
      "F1 Macro: 0.6482765551200884\n",
      "[[72 40]\n",
      " [30 58]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-06, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1989\t\n",
      "Training time: 51.67s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.200\n",
      "Accuracy: 0.71\n",
      "F1 Micro: 0.71\n",
      "F1 Macro: 0.7081320450885669\n",
      "[[79 33]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-05, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t22\t0.2080\t\n",
      "Training time: 49.72s, epochs: 22\n",
      "\n",
      "Least training loss reached: 0.212\n",
      "Accuracy: 0.66\n",
      "F1 Micro: 0.66\n",
      "F1 Macro: 0.6583257964023717\n",
      "[[73 39]\n",
      " [29 59]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-05, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t23\t0.1984\t\n",
      "Training time: 51.86s, epochs: 23\n",
      "\n",
      "Least training loss reached: 0.201\n",
      "Accuracy: 0.665\n",
      "F1 Micro: 0.665\n",
      "F1 Macro: 0.6649916247906198\n",
      "[[67 45]\n",
      " [22 66]]\n",
      "Training DSC with lr=0.1, bs=4000, mdl=1e-05, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t24\t0.1987\t\n",
      "Training time: 54.08s, epochs: 24\n",
      "\n",
      "Least training loss reached: 0.200\n",
      "Accuracy: 0.715\n",
      "F1 Micro: 0.715\n",
      "F1 Macro: 0.7141352591589558\n",
      "[[77 35]\n",
      " [22 66]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-07, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t862\t0.1985\t\n",
      "Training time: 1971.19s, epochs: 862\n",
      "\n",
      "Least training loss reached: 0.198\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6884735202492211\n",
      "[[76 36]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-07, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t431\t0.1915\t\n",
      "Training time: 994.62s, epochs: 431\n",
      "\n",
      "Least training loss reached: 0.192\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6892230576441103\n",
      "[[74 38]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-07, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t762\t0.1877\t\n",
      "Training time: 1760.65s, epochs: 762\n",
      "\n",
      "Least training loss reached: 0.188\n",
      "Accuracy: 0.67\n",
      "F1 Micro: 0.67\n",
      "F1 Macro: 0.6688077077478924\n",
      "[[73 39]\n",
      " [27 61]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-06, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t470\t0.1987\t\n",
      "Training time: 1084.17s, epochs: 470\n",
      "\n",
      "Least training loss reached: 0.199\n",
      "Accuracy: 0.685\n",
      "F1 Micro: 0.685\n",
      "F1 Macro: 0.6836634781953754\n",
      "[[75 37]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-06, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t464\t0.1915\t\n",
      "Training time: 1071.01s, epochs: 464\n",
      "\n",
      "Least training loss reached: 0.192\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6892230576441103\n",
      "[[74 38]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-06, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t772\t0.1876\t\n",
      "Training time: 1788.82s, epochs: 772\n",
      "\n",
      "Least training loss reached: 0.188\n",
      "Accuracy: 0.67\n",
      "F1 Micro: 0.67\n",
      "F1 Macro: 0.6688077077478924\n",
      "[[73 39]\n",
      " [27 61]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-05, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t114\t0.1999\t\n",
      "Training time: 262.58s, epochs: 114\n",
      "\n",
      "Least training loss reached: 0.200\n",
      "Accuracy: 0.7\n",
      "F1 Micro: 0.7\n",
      "F1 Macro: 0.6980676328502415\n",
      "[[78 34]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-05, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t154\t0.1927\t\n",
      "Training time: 355.91s, epochs: 154\n",
      "\n",
      "Least training loss reached: 0.193\n",
      "Accuracy: 0.67\n",
      "F1 Micro: 0.67\n",
      "F1 Macro: 0.6691729323308271\n",
      "[[72 40]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.01, bs=2000, mdl=1e-05, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t178\t0.1892\t\n",
      "Training time: 412.96s, epochs: 178\n",
      "\n",
      "Least training loss reached: 0.189\n",
      "Accuracy: 0.68\n",
      "F1 Micro: 0.68\n",
      "F1 Macro: 0.6791979949874687\n",
      "[[73 39]\n",
      " [25 63]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-07, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t28\t0.2045\t\n",
      "Training time: 64.88s, epochs: 28\n",
      "\n",
      "Least training loss reached: 0.204\n",
      "Accuracy: 0.675\n",
      "F1 Micro: 0.675\n",
      "F1 Macro: 0.674601386698706\n",
      "[[71 41]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-07, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t648\t0.1914\t\n",
      "Training time: 1497.87s, epochs: 648\n",
      "\n",
      "Least training loss reached: 0.192\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6892230576441103\n",
      "[[74 38]\n",
      " [24 64]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-07, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t765\t0.1878\t\n",
      "Training time: 1769.12s, epochs: 765\n",
      "\n",
      "Least training loss reached: 0.188\n",
      "Accuracy: 0.675\n",
      "F1 Micro: 0.675\n",
      "F1 Macro: 0.6740138920233707\n",
      "[[73 39]\n",
      " [26 62]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-06, nr=3\n",
      "Optimization started\n",
      "Processing epoch\t26\t0.2041\t\n",
      "Training time: 59.68s, epochs: 26\n",
      "\n",
      "Least training loss reached: 0.204\n",
      "Accuracy: 0.69\n",
      "F1 Micro: 0.69\n",
      "F1 Macro: 0.6874684948079444\n",
      "[[78 34]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-06, nr=5\n",
      "Optimization started\n",
      "Processing epoch\t26\t0.2007\t\n",
      "Training time: 59.94s, epochs: 26\n",
      "\n",
      "Least training loss reached: 0.201\n",
      "Accuracy: 0.67\n",
      "F1 Micro: 0.67\n",
      "F1 Macro: 0.6683750376846548\n",
      "[[74 38]\n",
      " [28 60]]\n",
      "Training DSC with lr=0.01, bs=3000, mdl=1e-06, nr=7\n",
      "Optimization started\n",
      "Processing epoch\t376\t0.1882\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m DSC \u001b[38;5;241m=\u001b[39m DSClassifierMultiQ(\u001b[38;5;241m2\u001b[39m, min_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, debug_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lr\u001b[38;5;241m=\u001b[39mlr, batch_size\u001b[38;5;241m=\u001b[39mbs,\n\u001b[0;32m     13\u001b[0m                 lossfn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_dloss\u001b[38;5;241m=\u001b[39mmdl, precompute_rules\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining DSC with lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, bs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mdl=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmdl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, nr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m losses, epoch, dt \u001b[38;5;241m=\u001b[39m \u001b[43mDSC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_single_rules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_rules_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_mult_rules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_final_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m DSC\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\dsgd\\DSClassifierMultiQ.py:100\u001b[0m, in \u001b[0;36mDSClassifierMultiQ.fit\u001b[1;34m(self, X, y, add_single_rules, single_rules_breaks, add_mult_rules, column_names, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_debug_step(X, y, optimizer, criterion, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_mode:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize(X, y, optimizer, criterion, )\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\dsgd\\DSClassifierMultiQ.py:181\u001b[0m, in \u001b[0;36mDSClassifierMultiQ._optimize_debug\u001b[1;34m(self, X, y, optimizer, criterion, print_init_model, print_final_model, print_time, print_partial_time, print_every_epochs, print_least_loss, return_partial_dt, disable_all_print, print_epoch_progress)\u001b[0m\n\u001b[0;32m    179\u001b[0m     acc_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# with torch.autograd.detect_anomaly():\u001b[39;49;00m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mni\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprint_epoch_progress\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:1083\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1081\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1083\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:1015\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1013\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DSCs = {}\n",
    "time = {}\n",
    "accuracys = {}\n",
    "learning_rates = [0.1, 0.01]\n",
    "batch_sizes = [2000, 3000, 4000]\n",
    "min_dl = [1e-7, 1e-6, 1e-5,]\n",
    "num_rules = [3, 5, 7,]\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for mdl in min_dl:\n",
    "            for nr in num_rules:\n",
    "                DSC = DSClassifierMultiQ(2, min_iter=20, max_iter=1000, debug_mode=True, lr=lr, batch_size=bs,\n",
    "                                lossfn=\"MSE\", num_workers=1, min_dloss=mdl, precompute_rules=True)\n",
    "                print(f\"Training DSC with lr={lr}, bs={bs}, mdl={mdl}, nr={nr}\")\n",
    "                losses, epoch, dt = DSC.fit(X, y, add_single_rules=True,\n",
    "                            single_rules_breaks=nr, add_mult_rules=False,\n",
    "                                column_names=df.columns[:-1], print_every_epochs=1, print_final_model=False)\n",
    "                y_pred = DSC.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "                print(f\"Accuracy: {acc}\")\n",
    "                print(f\"F1 Micro: {f1_micro}\")\n",
    "                print(f\"F1 Macro: {f1_macro}\")\n",
    "                print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
