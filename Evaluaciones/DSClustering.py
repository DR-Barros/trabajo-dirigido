from dsgd import DSClassifierMultiQ
import pandas as pd
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
import numpy as np

class DSClustering:
    def __init__(self, X, n_clusters, clusters_algorithms):
        self.X = X
        self.n_clusters = n_clusters
        self.clusters_algorithms = clusters_algorithms
        self.results = {}
        self.labels = None

    def compute_clusters(self):
        """
        Compute clusters using the specified clustering algorithms.
        Stores the labels in the `results` dictionary.
        """
        results = {}
        for model in self.clusters_algorithms:
            # Set n_clusters if applicable
            if hasattr(model, 'n_clusters') and getattr(model, 'n_clusters', None) is None:
                model.n_clusters = self.n_clusters
            
            model_name = model.__class__.__name__

            try:
                model.fit(self.X)
                if hasattr(model, 'labels_'):
                    labels = model.labels_
                else:
                    labels = model.fit_predict(self.X)
                results[model_name] = labels
            except Exception as e:
                raise ValueError(f"Error fitting model {model_name}: {e}")
        
        self.results = results

    def compare_clusters(self):
        """
        Compare the clusters generated by different algorithms.
        Prints contingency tables for all pairs.
        """
        if not self.results:
            raise ValueError("No clusters computed. Please run compute_clusters() first.")

        algorithms = list(self.results.keys())
        for i in range(len(algorithms)):
            for j in range(i + 1, len(algorithms)):
                alg1, alg2 = algorithms[i], algorithms[j]
                labels1, labels2 = self.results[alg1], self.results[alg2]
                contingency_table = pd.crosstab(pd.Series(labels1, name=alg1),
                                                pd.Series(labels2, name=alg2))
                print(f"Contingency Table between '{alg1}' and '{alg2}':")
                print(contingency_table)
                print()

    def normalize_clusters(self):
        """
        Normalize cluster labels for consistent comparison.
        Applies label encoding to each algorithm's result.
        """
        if not self.results:
            raise ValueError("No clusters computed. Please run compute_clusters() first.")
        # Use the labels from the first algorithm as reference
        algorithms = list(self.results.keys())
        labels1 = self.results[algorithms[0]]
        for alg in algorithms[1:]:
            labels2 = self.results[alg]
            updated_labels2 = np.copy(labels2)
            correspondence_dict = {}
            for l1, l2 in zip(labels1, labels2):
                if l1 != l2:
                    if l1 not in correspondence_dict:
                        correspondence_dict[l1] = l2
                for old_label, new_label in correspondence_dict.items():
                    updated_labels2[labels2 == new_label] = old_label
            self.results[alg] = updated_labels2
        
        
    def fit_dsc(self):
        X_values = self.X.values
        # Concatenate all cluster labels from different algorithms into a single vector
        Y_values = np.concatenate([labels for labels in self.results.values()]).reshape(-1, 1)
        X_values2 = np.concatenate([X_values] * len(self.results), axis=0)
        """ print("Fitting DSC with the following parameters:")
        print(f"Number of clusters: {self.n_clusters}")
        print(f"Shape of X_values: {X_values2.shape}")
        print(f"Shape of Y_values: {Y_values.shape}") """
        #recorremos X_values2 y Y_values y printeamos
        """ for i in range(len(X_values2)):
            print(f"X_values2[{i}]: {X_values2[i]}, Y_values[{i}]: {Y_values[i]}") """
        #cantidad de elementos en cada cluster
        print("Number of elements in each cluster:")
        for i in range(self.n_clusters):
            count = np.sum(Y_values == i)
            print(f"Cluster {i}: {count} elements")
        DSC = DSClassifierMultiQ(
            self.n_clusters,
            min_iter=20,
            max_iter=2000,
            debug_mode=True,
            lossfn="MSE",
            num_workers=0,
            min_dloss=1e-7,
            lr=0.01,
            precompute_rules=True
        )
        losses, epoch, dt = DSC.fit(
            X_values2,
            Y_values,
            add_single_rules=True,
            single_rules_breaks=3,
            add_mult_rules=False,
            column_names=self.X.columns,
            print_every_epochs=1
        )
        predictions = DSC.predict(X_values)
        self.labels = predictions
        DSC.print_most_important_rules(threshold=0.01)
        return self.labels
        