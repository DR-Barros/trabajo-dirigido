{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsgd import DSClustering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "#importamos los datasets clasico de sklearn\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, load_diabetes\n",
    "#normalizamos los datos\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    k = len(unique_labels)\n",
    "    \n",
    "    # Calcular el diámetro de cada clúster\n",
    "    diameters = []\n",
    "    for label in unique_labels:\n",
    "        cluster_points = X[labels == label]\n",
    "        if len(cluster_points) > 1:\n",
    "            diameters.append(np.max(cdist(cluster_points, cluster_points, metric='euclidean')))\n",
    "        else:\n",
    "            diameters.append(0)\n",
    "    \n",
    "    max_diameter = np.max(diameters)\n",
    "    \n",
    "    # Calcular la distancia mínima entre clusters\n",
    "    min_distances = []\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            cluster_i_points = X[labels == unique_labels[i]]\n",
    "            cluster_j_points = X[labels == unique_labels[j]]\n",
    "            min_distance = np.min(cdist(cluster_i_points, cluster_j_points, metric='euclidean'))\n",
    "            min_distances.append(min_distance)\n",
    "    \n",
    "    min_intercluster_distance = np.min(min_distances)\n",
    "    \n",
    "    # Índice de Dunn\n",
    "    dunn_index_value = min_intercluster_distance / max_diameter\n",
    "    \n",
    "    return dunn_index_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = pd.read_csv('data/Atom_Data.csv')\n",
    "atom_labels = pd.read_csv('data/Atom_Labels.csv')\n",
    "chainlink = pd.read_csv('data/Chainlink_Data.csv')\n",
    "chainlink_labels = pd.read_csv('data/Chainlink_Labels.csv')\n",
    "engytime = pd.read_csv('data/EngyTime_Data.csv')\n",
    "engytime_labels = pd.read_csv('data/EngyTime_Labels.csv')\n",
    "hepta = pd.read_csv('data/Hepta_Data.csv')\n",
    "hepta_labels = pd.read_csv('data/Hepta_Labels.csv')\n",
    "tetra = pd.read_csv('data/Tetra_Data.csv')\n",
    "tetra_labels = pd.read_csv('data/Tetra_Labels.csv')\n",
    "target = pd.read_csv('data/Target_Data.csv')\n",
    "target_labels = pd.read_csv('data/Target_Labels.csv')\n",
    "two_diamonds = pd.read_csv('data/TwoDiamonds_Data.csv')\n",
    "two_diamonds_labels = pd.read_csv('data/TwoDiamonds_Labels.csv')\n",
    "wing_nut = pd.read_csv('data/WingNut_Data.csv')\n",
    "wing_nut_labels = pd.read_csv('data/WingNut_Labels.csv')\n",
    "# Cargamos los datasets clasico de sklearn\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_labels = pd.DataFrame(iris.target, columns=['target'])\n",
    "digits = load_digits()\n",
    "digits_data = pd.DataFrame(digits.data, columns=digits.feature_names)\n",
    "digits_labels = pd.DataFrame(digits.target, columns=['target'])\n",
    "wine = load_wine()\n",
    "wine_data = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_labels = pd.DataFrame(wine.target, columns=['target'])\n",
    "breast_cancer = load_breast_cancer()\n",
    "breast_cancer_data = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "breast_cancer_labels = pd.DataFrame(breast_cancer.target, columns=['target'])\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'Atom',\n",
    "        'data': atom,\n",
    "        'labels': atom_labels,\n",
    "        'n_clusters': atom_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Chainlink',\n",
    "        'data': chainlink,\n",
    "        'labels': chainlink_labels,\n",
    "        'n_clusters': chainlink_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'EngyTime',\n",
    "        'data': engytime,\n",
    "        'labels': engytime_labels,\n",
    "        'n_clusters': engytime_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Hepta',\n",
    "        'data': hepta,\n",
    "        'labels': hepta_labels,\n",
    "        'n_clusters': hepta_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tetra',\n",
    "        'data': tetra,\n",
    "        'labels': tetra_labels,\n",
    "        'n_clusters': tetra_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Target',\n",
    "        'data': target,\n",
    "        'labels': target_labels,\n",
    "        'n_clusters': target_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'TwoDiamonds',\n",
    "        'data': two_diamonds,\n",
    "        'labels': two_diamonds_labels,\n",
    "        'n_clusters': two_diamonds_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'WingNut',\n",
    "        'data': wing_nut,\n",
    "        'labels': wing_nut_labels,\n",
    "        'n_clusters': wing_nut_labels.nunique().values[0]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Iris',\n",
    "        'data': iris_data,\n",
    "        'labels': iris_labels,\n",
    "        'n_clusters': 3\n",
    "    },\n",
    "    {\n",
    "        'name': 'Digits',\n",
    "        'data': digits_data,\n",
    "        'labels': digits_labels,\n",
    "        'n_clusters': 10\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wine',\n",
    "        'data': wine_data,\n",
    "        'labels': wine_labels,\n",
    "        'n_clusters': 3\n",
    "    },\n",
    "    {\n",
    "        'name': 'BreastCancer',\n",
    "        'data': breast_cancer_data,\n",
    "        'labels': breast_cancer_labels,\n",
    "        'n_clusters': 2\n",
    "    },\n",
    "]\n",
    "#Resultados\n",
    "results_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t373\t0.0009\t\n",
      "Training time: 38.33s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t373\t0.0009\t\n",
      "Training time: 38.56s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0019\t\n",
      "Training time: 36.14s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.002\n",
      "Dataset:  Atom\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t311\t0.0019\t\n",
      "Training time: 36.25s, epochs: 312\n",
      "\n",
      "Least training loss reached: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t342\t0.0016\t\n",
      "Training time: 43.07s, epochs: 370\n",
      "\n",
      "Least training loss reached: 0.001\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0029\t\n",
      "Training time: 45.08s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.002\n",
      "Dataset:  Chainlink\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0014\t\n",
      "Training time: 185.63s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t218\t0.0026\t\n",
      "Training time: 114.20s, epochs: 246\n",
      "\n",
      "Least training loss reached: 0.002\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0015\t\n",
      "Training time: 177.60s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n",
      "Dataset:  EngyTime\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t311\t0.0000\t\n",
      "Training time: 8.85s, epochs: 311\n",
      "\n",
      "Least training loss reached: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t311\t0.0000\t\n",
      "Training time: 8.85s, epochs: 311\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Optimization started\n",
      "Processing epoch\t94\t0.0009\t\n",
      "Training time: 3.13s, epochs: 119\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Dataset:  Hepta\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0001\t\n",
      "Training time: 20.39s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t373\t0.0001\t\n",
      "Training time: 20.37s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0001\t\n",
      "Training time: 20.34s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Dataset:  Tetra\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t94\t0.0046\t\n",
      "Training time: 8.96s, epochs: 101\n",
      "\n",
      "Least training loss reached: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t187\t0.0031\t\n",
      "Training time: 16.80s, epochs: 188\n",
      "\n",
      "Least training loss reached: 0.003\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0005\t\n",
      "Training time: 37.58s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Dataset:  Target\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0003\t\n",
      "Training time: 37.10s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t373\t0.0003\t\n",
      "Training time: 37.20s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0012\t\n",
      "Training time: 35.70s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n",
      "Dataset:  TwoDiamonds\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0013\t\n",
      "Training time: 46.31s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t94\t0.0071\t\n",
      "Training time: 13.37s, epochs: 116\n",
      "\n",
      "Least training loss reached: 0.004\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0023\t\n",
      "Training time: 45.31s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.002\n",
      "Dataset:  WingNut\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0003\t\n",
      "Training time: 8.94s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Optimization started\n",
      "Processing epoch\t1\t1.0000\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch\t373\t0.0003\t\n",
      "Training time: 8.99s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0004\t\n",
      "Training time: 9.09s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Dataset:  Iris\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t32\t0.1875\t\n",
      "Training time: 189.81s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t32\t0.2222\t\n",
      "Training time: 181.55s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.222\n",
      "Optimization started\n",
      "Processing epoch\t32\t0.0900\t\n",
      "Training time: 263.80s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.090\n",
      "Dataset:  Digits\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0001\t\n",
      "Training time: 21.36s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t63\t0.0196\t\n",
      "Training time: 4.74s, epochs: 91\n",
      "\n",
      "Least training loss reached: 0.004\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0002\t\n",
      "Training time: 21.22s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.000\n",
      "Dataset:  Wine\n",
      "-----------------------------\n",
      "Optimization started\n",
      "Processing epoch\t32\t0.1875\t\n",
      "Training time: 19.48s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\trabajo-dirigido\\env\\Lib\\site-packages\\cdsgd\\ClusteringSelector.py:248: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  row_modes[0][x] = self.get_best_labels()[x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "Processing epoch\t32\t0.1875\t\n",
      "Training time: 19.48s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.188\n",
      "Optimization started\n",
      "Processing epoch\t32\t0.2500\t\n",
      "Training time: 17.99s, epochs: 52\n",
      "\n",
      "Least training loss reached: 0.250\n",
      "Dataset:  BreastCancer\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#Iteramos sobre los datasets\n",
    "for dataset in datasets:\n",
    "    n_clusters = dataset['n_clusters']\n",
    "    data = dataset['data']\n",
    "    #normalizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data, columns=dataset['data'].columns)\n",
    "\n",
    "    #KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans_labels = kmeans.fit_predict(data)\n",
    "    kmeans_silhouette = silhouette_score(data, kmeans_labels)\n",
    "    kmeans_dunn = dunn_index(data, kmeans_labels)\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'KMeans',\n",
    "        'Silhouette': kmeans_silhouette,\n",
    "        'Dunn': kmeans_dunn\n",
    "    }]\n",
    "\n",
    "    #DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5)\n",
    "    dbscan_labels = dbscan.fit_predict(data)\n",
    "    if len(np.unique(dbscan_labels)) > 1:\n",
    "        dbscan_silhouette = silhouette_score(data, dbscan_labels)\n",
    "        dbscan_dunn = dunn_index(data, dbscan_labels)\n",
    "    else:\n",
    "        dbscan_silhouette = 0\n",
    "        dbscan_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'DBSCAN',\n",
    "        'Silhouette': dbscan_silhouette,\n",
    "        'Dunn': dbscan_dunn\n",
    "    }]\n",
    "\n",
    "    #Agglomerative\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    agglomerative_labels = agglomerative.fit_predict(data)\n",
    "    agglomerative_silhouette = silhouette_score(data, agglomerative_labels)\n",
    "    agglomerative_dunn = dunn_index(data, agglomerative_labels)\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'Agglomerative',\n",
    "        'Silhouette': agglomerative_silhouette,\n",
    "        'Dunn': agglomerative_dunn\n",
    "    }]\n",
    "\n",
    "    #CDSDG\n",
    "    cdsgd = DSClustering(data=data)\n",
    "    cdsgd.generate_categorical_rules()\n",
    "    cdsgd_labels = cdsgd.predict()\n",
    "    if len(np.unique(cdsgd_labels)) > 1:\n",
    "        cdsgd_silhouette = silhouette_score(data, cdsgd_labels)\n",
    "        cdsgd_dunn = dunn_index(data, cdsgd_labels)\n",
    "    else:\n",
    "        cdsgd_silhouette = 0\n",
    "        cdsgd_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Clustering',\n",
    "        'Silhouette': cdsgd_silhouette,\n",
    "        'Dunn': cdsgd_dunn\n",
    "    }]\n",
    "\n",
    "    #CDSDG mas votados\n",
    "    cdsgd1 = DSClustering(data=data, most_voted=True)\n",
    "    cdsgd1.generate_categorical_rules()\n",
    "    cdsgd1_labels = cdsgd1.predict()\n",
    "    if len(np.unique(cdsgd1_labels)) > 1:\n",
    "        cdsgd1_silhouette = silhouette_score(data, cdsgd1_labels)\n",
    "        cdsgd1_dunn = dunn_index(data, cdsgd1_labels)\n",
    "    else:\n",
    "        cdsgd1_silhouette = 0\n",
    "        cdsgd1_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Voting',\n",
    "        'Silhouette': cdsgd1_silhouette,\n",
    "        'Dunn': cdsgd1_dunn\n",
    "    }]\n",
    "\n",
    "    # CDSDG con numero de clusters\n",
    "    cdsgd2 = DSClustering(data=data, cluster=n_clusters)\n",
    "    cdsgd2.generate_categorical_rules()\n",
    "    cdsgd2_labels = cdsgd2.predict()\n",
    "    if len(np.unique(cdsgd2_labels)) > 1:\n",
    "        cdsgd2_silhouette = silhouette_score(data, cdsgd2_labels)\n",
    "        cdsgd2_dunn = dunn_index(data, cdsgd2_labels)\n",
    "    else:\n",
    "        cdsgd2_silhouette = 0\n",
    "        cdsgd2_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Clustering with n_clusters',\n",
    "        'Silhouette': cdsgd2_silhouette,\n",
    "        'Dunn': cdsgd2_dunn\n",
    "    }]\n",
    "    print(\"Dataset: \", dataset['name'])\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_df)\n",
    "#save results\n",
    "results_df.to_csv('results1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom\n",
      "  Dataset                         Algorithm  Silhouette  Dunn\n",
      "1    Atom                            DBSCAN        0.46  0.02\n",
      "4    Atom                            DBSCAN        0.46  0.02\n",
      "6    Atom                  CDSDG Clustering        0.45  0.04\n",
      "7    Atom                      CDSDG Voting        0.45  0.04\n",
      "8    Atom  CDSDG Clustering with n_clusters        0.39  0.03\n",
      "0    Atom                            KMeans        0.38  0.06\n",
      "2    Atom                     Agglomerative        0.38  0.07\n",
      "3    Atom                            KMeans        0.38  0.04\n",
      "5    Atom                     Agglomerative        0.38  0.07\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Chainlink\n",
      "      Dataset                         Algorithm  Silhouette  Dunn\n",
      "12  Chainlink                  CDSDG Clustering        0.43  0.01\n",
      "13  Chainlink                      CDSDG Voting        0.43  0.01\n",
      "9   Chainlink                            KMeans        0.28  0.02\n",
      "11  Chainlink                     Agglomerative        0.27  0.02\n",
      "14  Chainlink  CDSDG Clustering with n_clusters        0.25  0.01\n",
      "10  Chainlink                            DBSCAN        0.15  0.22\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "EngyTime\n",
      "     Dataset                         Algorithm  Silhouette  Dunn\n",
      "15  EngyTime                            KMeans        0.41  0.00\n",
      "17  EngyTime                     Agglomerative        0.41  0.00\n",
      "18  EngyTime                  CDSDG Clustering        0.41  0.00\n",
      "20  EngyTime  CDSDG Clustering with n_clusters        0.41  0.00\n",
      "16  EngyTime                            DBSCAN        0.38  0.04\n",
      "19  EngyTime                      CDSDG Voting       -0.02  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Hepta\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "21   Hepta                            KMeans         0.7  1.05\n",
      "22   Hepta                            DBSCAN         0.7  1.05\n",
      "23   Hepta                     Agglomerative         0.7  1.05\n",
      "24   Hepta                  CDSDG Clustering         0.7  1.05\n",
      "25   Hepta                      CDSDG Voting         0.7  1.05\n",
      "26   Hepta  CDSDG Clustering with n_clusters         0.7  1.05\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Tetra\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "27   Tetra                            KMeans        0.51  0.22\n",
      "29   Tetra                     Agglomerative        0.50  0.14\n",
      "30   Tetra                  CDSDG Clustering        0.50  0.05\n",
      "31   Tetra                      CDSDG Voting        0.49  0.04\n",
      "32   Tetra  CDSDG Clustering with n_clusters        0.49  0.04\n",
      "28   Tetra                            DBSCAN        0.31  0.10\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Target\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "33  Target                            KMeans        0.58  0.02\n",
      "38  Target  CDSDG Clustering with n_clusters        0.58  0.02\n",
      "35  Target                     Agglomerative        0.57  0.04\n",
      "36  Target                  CDSDG Clustering        0.55  0.26\n",
      "37  Target                      CDSDG Voting        0.34  0.01\n",
      "34  Target                            DBSCAN        0.28  0.12\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "TwoDiamonds\n",
      "        Dataset                         Algorithm  Silhouette  Dunn\n",
      "42  TwoDiamonds                  CDSDG Clustering        0.45  0.02\n",
      "43  TwoDiamonds                      CDSDG Voting        0.45  0.02\n",
      "39  TwoDiamonds                            KMeans        0.42  0.02\n",
      "41  TwoDiamonds                     Agglomerative        0.42  0.02\n",
      "44  TwoDiamonds  CDSDG Clustering with n_clusters        0.42  0.02\n",
      "40  TwoDiamonds                            DBSCAN        0.00  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "WingNut\n",
      "    Dataset                         Algorithm  Silhouette  Dunn\n",
      "45  WingNut                            KMeans        0.44  0.02\n",
      "50  WingNut  CDSDG Clustering with n_clusters        0.44  0.02\n",
      "48  WingNut                  CDSDG Clustering        0.42  0.01\n",
      "47  WingNut                     Agglomerative        0.41  0.07\n",
      "49  WingNut                      CDSDG Voting        0.28  0.01\n",
      "46  WingNut                            DBSCAN        0.00  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Iris\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "56    Iris  CDSDG Clustering with n_clusters        0.58  0.27\n",
      "54    Iris                  CDSDG Clustering        0.50  0.24\n",
      "51    Iris                            KMeans        0.46  0.08\n",
      "53    Iris                     Agglomerative        0.45  0.10\n",
      "52    Iris                            DBSCAN        0.36  0.05\n",
      "55    Iris                      CDSDG Voting        0.29  0.05\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Digits\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "57  Digits                            KMeans        0.14  0.03\n",
      "59  Digits                     Agglomerative        0.13  0.05\n",
      "58  Digits                            DBSCAN        0.00  0.00\n",
      "60  Digits                  CDSDG Clustering        0.00  0.00\n",
      "61  Digits                      CDSDG Voting        0.00  0.00\n",
      "62  Digits  CDSDG Clustering with n_clusters        0.00  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Wine\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "63    Wine                            KMeans        0.28  0.22\n",
      "65    Wine                     Agglomerative        0.28  0.23\n",
      "68    Wine  CDSDG Clustering with n_clusters        0.28  0.23\n",
      "66    Wine                  CDSDG Clustering        0.24  0.14\n",
      "67    Wine                      CDSDG Voting        0.23  0.16\n",
      "64    Wine                            DBSCAN        0.00  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "BreastCancer\n",
      "         Dataset                         Algorithm  Silhouette  Dunn\n",
      "69  BreastCancer                            KMeans        0.34  0.06\n",
      "71  BreastCancer                     Agglomerative        0.34  0.07\n",
      "70  BreastCancer                            DBSCAN        0.00  0.00\n",
      "72  BreastCancer                  CDSDG Clustering        0.00  0.00\n",
      "73  BreastCancer                      CDSDG Voting        0.00  0.00\n",
      "74  BreastCancer  CDSDG Clustering with n_clusters        0.00  0.00\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv('results1.csv')\n",
    "# Mostar resultados en una tabla\n",
    "for dataset in results_df['Dataset'].unique():\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset].round(2)\n",
    "    dataset_results = dataset_results.sort_values(by='Silhouette', ascending=False)\n",
    "    print(dataset)\n",
    "    print(dataset_results)\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
