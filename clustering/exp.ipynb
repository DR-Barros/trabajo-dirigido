{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsgd import DSClustering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris,load_wine,\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    k = len(unique_labels)\n",
    "    \n",
    "    # Calcular el diámetro de cada clúster\n",
    "    diameters = []\n",
    "    for label in unique_labels:\n",
    "        cluster_points = X[labels == label]\n",
    "        if len(cluster_points) > 1:\n",
    "            diameters.append(np.max(cdist(cluster_points, cluster_points, metric='euclidean')))\n",
    "        else:\n",
    "            diameters.append(0)\n",
    "    \n",
    "    max_diameter = np.max(diameters)\n",
    "    \n",
    "    # Calcular la distancia mínima entre clusters\n",
    "    min_distances = []\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            cluster_i_points = X[labels == unique_labels[i]]\n",
    "            cluster_j_points = X[labels == unique_labels[j]]\n",
    "            min_distance = np.min(cdist(cluster_i_points, cluster_j_points, metric='euclidean'))\n",
    "            min_distances.append(min_distance)\n",
    "    \n",
    "    min_intercluster_distance = np.min(min_distances)\n",
    "    \n",
    "    # Índice de Dunn\n",
    "    dunn_index_value = min_intercluster_distance / max_diameter\n",
    "    \n",
    "    return dunn_index_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = pd.read_csv('data/Atom_Data.csv')\n",
    "atom_labels = pd.read_csv('data/Atom_Labels.csv')\n",
    "chainlink = pd.read_csv('data/Chainlink_Data.csv')\n",
    "chainlink_labels = pd.read_csv('data/Chainlink_Labels.csv')\n",
    "engytime = pd.read_csv('data/EngyTime_Data.csv')\n",
    "engytime_labels = pd.read_csv('data/EngyTime_Labels.csv')\n",
    "hepta = pd.read_csv('data/Hepta_Data.csv')\n",
    "hepta_labels = pd.read_csv('data/Hepta_Labels.csv')\n",
    "tetra = pd.read_csv('data/Tetra_Data.csv')\n",
    "tetra_labels = pd.read_csv('data/Tetra_Labels.csv')\n",
    "target = pd.read_csv('data/Target_Data.csv')\n",
    "target_labels = pd.read_csv('data/Target_Labels.csv')\n",
    "two_diamonds = pd.read_csv('data/TwoDiamonds_Data.csv')\n",
    "two_diamonds_labels = pd.read_csv('data/TwoDiamonds_Labels.csv')\n",
    "wing_nut = pd.read_csv('data/WingNut_Data.csv')\n",
    "wing_nut_labels = pd.read_csv('data/WingNut_Labels.csv')\n",
    "# Cargamos los datasets clasico de sklearn\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_labels = pd.DataFrame(iris.target, columns=['target'])\n",
    "wine = load_wine()\n",
    "wine_data = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_labels = pd.DataFrame(wine.target, columns=['target'])\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'Atom',\n",
    "        'data': atom,\n",
    "        'labels': atom_labels,\n",
    "        'n_clusters': atom_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Chainlink',\n",
    "        'data': chainlink,\n",
    "        'labels': chainlink_labels,\n",
    "        'n_clusters': chainlink_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'EngyTime',\n",
    "        'data': engytime,\n",
    "        'labels': engytime_labels,\n",
    "        'n_clusters': engytime_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Hepta',\n",
    "        'data': hepta,\n",
    "        'labels': hepta_labels,\n",
    "        'n_clusters': hepta_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Tetra',\n",
    "        'data': tetra,\n",
    "        'labels': tetra_labels,\n",
    "        'n_clusters': tetra_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Target',\n",
    "        'data': target,\n",
    "        'labels': target_labels,\n",
    "        'n_clusters': target_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'TwoDiamonds',\n",
    "        'data': two_diamonds,\n",
    "        'labels': two_diamonds_labels,\n",
    "        'n_clusters': two_diamonds_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'WingNut',\n",
    "        'data': wing_nut,\n",
    "        'labels': wing_nut_labels,\n",
    "        'n_clusters': wing_nut_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Iris',\n",
    "        'data': iris_data,\n",
    "        'labels': iris_labels,\n",
    "        'n_clusters': 3\n",
    "    },{\n",
    "        'name': 'Wine',\n",
    "        'data': wine_data,\n",
    "        'labels': wine_labels,\n",
    "        'n_clusters': 3\n",
    "    },\n",
    "]\n",
    "#Resultados\n",
    "results_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iteramos sobre los datasets\n",
    "for dataset in datasets:\n",
    "    n_clusters = dataset['n_clusters']\n",
    "    data = dataset['data']\n",
    "    #normalizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data, columns=dataset['data'].columns)\n",
    "\n",
    "    #KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans_labels = kmeans.fit_predict(data)\n",
    "    kmeans_silhouette = silhouette_score(data, kmeans_labels)\n",
    "    kmeans_dunn = dunn_index(data, kmeans_labels)\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'KMeans',\n",
    "        'Silhouette': kmeans_silhouette,\n",
    "        'Dunn': kmeans_dunn\n",
    "    }]\n",
    "\n",
    "    #DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5)\n",
    "    dbscan_labels = dbscan.fit_predict(data)\n",
    "    if len(np.unique(dbscan_labels)) > 1:\n",
    "        dbscan_silhouette = silhouette_score(data, dbscan_labels)\n",
    "        dbscan_dunn = dunn_index(data, dbscan_labels)\n",
    "    else:\n",
    "        dbscan_silhouette = 0\n",
    "        dbscan_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'DBSCAN',\n",
    "        'Silhouette': dbscan_silhouette,\n",
    "        'Dunn': dbscan_dunn\n",
    "    }]\n",
    "\n",
    "    #Agglomerative\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    agglomerative_labels = agglomerative.fit_predict(data)\n",
    "    agglomerative_silhouette = silhouette_score(data, agglomerative_labels)\n",
    "    agglomerative_dunn = dunn_index(data, agglomerative_labels)\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'Agglomerative',\n",
    "        'Silhouette': agglomerative_silhouette,\n",
    "        'Dunn': agglomerative_dunn\n",
    "    }]\n",
    "\n",
    "    #CDSDG\n",
    "    cdsgd = DSClustering(data=data)\n",
    "    cdsgd.generate_categorical_rules()\n",
    "    cdsgd_labels = cdsgd.predict()\n",
    "    if len(np.unique(cdsgd_labels)) > 1:\n",
    "        cdsgd_silhouette = silhouette_score(data, cdsgd_labels)\n",
    "        cdsgd_dunn = dunn_index(data, cdsgd_labels)\n",
    "    else:\n",
    "        cdsgd_silhouette = 0\n",
    "        cdsgd_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Clustering',\n",
    "        'Silhouette': cdsgd_silhouette,\n",
    "        'Dunn': cdsgd_dunn\n",
    "    }]\n",
    "\n",
    "    #CDSDG mas votados\n",
    "    cdsgd1 = DSClustering(data=data, most_voted=True)\n",
    "    cdsgd1.generate_categorical_rules()\n",
    "    cdsgd1_labels = cdsgd1.predict()\n",
    "    if len(np.unique(cdsgd1_labels)) > 1:\n",
    "        cdsgd1_silhouette = silhouette_score(data, cdsgd1_labels)\n",
    "        cdsgd1_dunn = dunn_index(data, cdsgd1_labels)\n",
    "    else:\n",
    "        cdsgd1_silhouette = 0\n",
    "        cdsgd1_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Voting',\n",
    "        'Silhouette': cdsgd1_silhouette,\n",
    "        'Dunn': cdsgd1_dunn\n",
    "    }]\n",
    "\n",
    "    # CDSDG con numero de clusters\n",
    "    cdsgd2 = DSClustering(data=data, cluster=n_clusters)\n",
    "    cdsgd2.generate_categorical_rules()\n",
    "    cdsgd2_labels = cdsgd2.predict()\n",
    "    if len(np.unique(cdsgd2_labels)) > 1:\n",
    "        cdsgd2_silhouette = silhouette_score(data, cdsgd2_labels)\n",
    "        cdsgd2_dunn = dunn_index(data, cdsgd2_labels)\n",
    "    else:\n",
    "        cdsgd2_silhouette = 0\n",
    "        cdsgd2_dunn = 0\n",
    "    results_df = results_df + [{\n",
    "        'Dataset': dataset['name'],\n",
    "        'Algorithm': 'CDSDG Clustering with n_clusters',\n",
    "        'Silhouette': cdsgd2_silhouette,\n",
    "        'Dunn': cdsgd2_dunn\n",
    "    }]\n",
    "    print(\"Dataset: \", dataset['name'])\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_df)\n",
    "#save results\n",
    "results_df.to_csv('results2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom\n",
      "  Dataset                         Algorithm  Silhouette   Dunn\n",
      "0    Atom                            KMeans       0.378  0.057\n",
      "1    Atom                            DBSCAN       0.461  0.019\n",
      "2    Atom                     Agglomerative       0.384  0.068\n",
      "3    Atom                            KMeans       0.385  0.041\n",
      "4    Atom                            DBSCAN       0.461  0.019\n",
      "5    Atom                     Agglomerative       0.384  0.068\n",
      "6    Atom                  CDSDG Clustering       0.453  0.036\n",
      "7    Atom                      CDSDG Voting       0.453  0.036\n",
      "8    Atom  CDSDG Clustering with n_clusters       0.388  0.027\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Chainlink\n",
      "      Dataset                         Algorithm  Silhouette   Dunn\n",
      "9   Chainlink                            KMeans       0.283  0.016\n",
      "10  Chainlink                            DBSCAN       0.154  0.221\n",
      "11  Chainlink                     Agglomerative       0.272  0.019\n",
      "12  Chainlink                  CDSDG Clustering       0.435  0.009\n",
      "13  Chainlink                      CDSDG Voting       0.435  0.009\n",
      "14  Chainlink  CDSDG Clustering with n_clusters       0.248  0.015\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "EngyTime\n",
      "     Dataset                         Algorithm  Silhouette   Dunn\n",
      "15  EngyTime                            KMeans       0.413  0.001\n",
      "16  EngyTime                            DBSCAN       0.382  0.036\n",
      "17  EngyTime                     Agglomerative       0.408  0.004\n",
      "18  EngyTime                  CDSDG Clustering       0.414  0.003\n",
      "19  EngyTime                      CDSDG Voting      -0.023  0.002\n",
      "20  EngyTime  CDSDG Clustering with n_clusters       0.413  0.001\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Hepta\n",
      "   Dataset                         Algorithm  Silhouette  Dunn\n",
      "21   Hepta                            KMeans       0.702  1.05\n",
      "22   Hepta                            DBSCAN       0.702  1.05\n",
      "23   Hepta                     Agglomerative       0.702  1.05\n",
      "24   Hepta                  CDSDG Clustering       0.702  1.05\n",
      "25   Hepta                      CDSDG Voting       0.702  1.05\n",
      "26   Hepta  CDSDG Clustering with n_clusters       0.702  1.05\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Tetra\n",
      "   Dataset                         Algorithm  Silhouette   Dunn\n",
      "27   Tetra                            KMeans       0.506  0.224\n",
      "28   Tetra                            DBSCAN       0.307  0.101\n",
      "29   Tetra                     Agglomerative       0.495  0.143\n",
      "30   Tetra                  CDSDG Clustering       0.497  0.048\n",
      "31   Tetra                      CDSDG Voting       0.493  0.042\n",
      "32   Tetra  CDSDG Clustering with n_clusters       0.489  0.042\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Target\n",
      "   Dataset                         Algorithm  Silhouette   Dunn\n",
      "33  Target                            KMeans       0.580  0.023\n",
      "34  Target                            DBSCAN       0.276  0.116\n",
      "35  Target                     Agglomerative       0.568  0.044\n",
      "36  Target                  CDSDG Clustering       0.551  0.262\n",
      "37  Target                      CDSDG Voting       0.343  0.008\n",
      "38  Target  CDSDG Clustering with n_clusters       0.581  0.015\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "TwoDiamonds\n",
      "        Dataset                         Algorithm  Silhouette   Dunn\n",
      "39  TwoDiamonds                            KMeans       0.425  0.017\n",
      "40  TwoDiamonds                            DBSCAN       0.000  0.000\n",
      "41  TwoDiamonds                     Agglomerative       0.425  0.017\n",
      "42  TwoDiamonds                  CDSDG Clustering       0.447  0.015\n",
      "43  TwoDiamonds                      CDSDG Voting       0.447  0.015\n",
      "44  TwoDiamonds  CDSDG Clustering with n_clusters       0.425  0.017\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "WingNut\n",
      "    Dataset                         Algorithm  Silhouette   Dunn\n",
      "45  WingNut                            KMeans       0.438  0.015\n",
      "46  WingNut                            DBSCAN       0.000  0.000\n",
      "47  WingNut                     Agglomerative       0.412  0.071\n",
      "48  WingNut                  CDSDG Clustering       0.415  0.014\n",
      "49  WingNut                      CDSDG Voting       0.280  0.010\n",
      "50  WingNut  CDSDG Clustering with n_clusters       0.438  0.015\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Iris\n",
      "   Dataset                         Algorithm  Silhouette   Dunn\n",
      "51    Iris                            KMeans       0.457  0.078\n",
      "52    Iris                            DBSCAN       0.357  0.048\n",
      "53    Iris                     Agglomerative       0.447  0.098\n",
      "54    Iris                  CDSDG Clustering       0.505  0.239\n",
      "55    Iris                      CDSDG Voting       0.293  0.054\n",
      "56    Iris  CDSDG Clustering with n_clusters       0.582  0.267\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Digits\n",
      "   Dataset                         Algorithm  Silhouette   Dunn\n",
      "57  Digits                            KMeans       0.145  0.034\n",
      "58  Digits                            DBSCAN       0.000  0.000\n",
      "59  Digits                     Agglomerative       0.125  0.054\n",
      "60  Digits                  CDSDG Clustering       0.000  0.000\n",
      "61  Digits                      CDSDG Voting       0.000  0.000\n",
      "62  Digits  CDSDG Clustering with n_clusters       0.000  0.000\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Wine\n",
      "   Dataset                         Algorithm  Silhouette   Dunn\n",
      "63    Wine                            KMeans       0.283  0.220\n",
      "64    Wine                            DBSCAN       0.000  0.000\n",
      "65    Wine                     Agglomerative       0.277  0.229\n",
      "66    Wine                  CDSDG Clustering       0.244  0.137\n",
      "67    Wine                      CDSDG Voting       0.228  0.160\n",
      "68    Wine  CDSDG Clustering with n_clusters       0.285  0.232\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "BreastCancer\n",
      "         Dataset                         Algorithm  Silhouette   Dunn\n",
      "69  BreastCancer                            KMeans       0.343  0.061\n",
      "70  BreastCancer                            DBSCAN       0.000  0.000\n",
      "71  BreastCancer                     Agglomerative       0.339  0.072\n",
      "72  BreastCancer                  CDSDG Clustering       0.000  0.000\n",
      "73  BreastCancer                      CDSDG Voting       0.000  0.000\n",
      "74  BreastCancer  CDSDG Clustering with n_clusters       0.000  0.000\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv('results1.csv')\n",
    "# Mostar resultados en una tabla\n",
    "for dataset in results_df['Dataset'].unique():\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset].round(3)\n",
    "    print(dataset)\n",
    "    print(dataset_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
