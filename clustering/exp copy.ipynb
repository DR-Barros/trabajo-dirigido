{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asttokens==2.4.1\n",
      "cdsgd @ git+https://github.com/ricardo-valdivia/CDSGD.git@aae1e2d49cc5e015cf50643ecaeb4090d0c4d2d3\n",
      "cloudpickle==3.0.0\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.2.1\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.2\n",
      "decorator==5.1.1\n",
      "dill==0.3.8\n",
      "dsgd @ git+https://github.com/Sergio-P/DSGD.git@7d9bb9f0b417582040a3e3a964997a1e853dd820\n",
      "executing==2.0.1\n",
      "filelock==3.15.4\n",
      "fonttools==4.53.1\n",
      "fsspec==2024.6.1\n",
      "imageio==2.34.2\n",
      "intel-openmp==2021.4.0\n",
      "ipykernel==6.29.5\n",
      "ipython==8.26.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "joblib==1.4.2\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.5\n",
      "lazy_loader==0.4\n",
      "lime==0.2.0.1\n",
      "llvmlite==0.43.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib==3.9.1\n",
      "matplotlib-inline==0.1.7\n",
      "mkl==2021.4.0\n",
      "mpmath==1.3.0\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.3\n",
      "numba==0.60.0\n",
      "numpy==1.26.4\n",
      "packaging==24.1\n",
      "pandas==2.2.2\n",
      "parso==0.8.4\n",
      "pillow==10.4.0\n",
      "platformdirs==4.2.2\n",
      "prompt_toolkit==3.0.47\n",
      "psutil==6.0.0\n",
      "pure-eval==0.2.2\n",
      "Pygments==2.18.0\n",
      "pyparsing==3.1.2\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.1\n",
      "pywin32==306\n",
      "pyzmq==26.0.3\n",
      "scikit-image==0.24.0\n",
      "scikit-learn==1.5.1\n",
      "scipy==1.14.0\n",
      "shap==0.46.0\n",
      "six==1.16.0\n",
      "slicer==0.0.8\n",
      "stack-data==0.6.3\n",
      "sympy==1.12.1\n",
      "tbb==2021.13.0\n",
      "threadpoolctl==3.5.0\n",
      "tifffile==2024.7.24\n",
      "torch==2.3.1\n",
      "tornado==6.4.1\n",
      "tqdm==4.66.4\n",
      "traitlets==5.14.3\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.1\n",
      "wcwidth==0.2.13\n",
      "wittgenstein==0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsgd import DSClustering\n",
    "from dsgd import DSClassifierMultiQ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris,load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import wittgenstein as lw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = pd.read_csv('data/Atom_Data.csv')\n",
    "atom_labels = pd.read_csv('data/Atom_Labels.csv')\n",
    "chainlink = pd.read_csv('data/Chainlink_Data.csv')\n",
    "chainlink_labels = pd.read_csv('data/Chainlink_Labels.csv')\n",
    "engytime = pd.read_csv('data/EngyTime_Data.csv')\n",
    "engytime_labels = pd.read_csv('data/EngyTime_Labels.csv')\n",
    "hepta = pd.read_csv('data/Hepta_Data.csv')\n",
    "hepta_labels = pd.read_csv('data/Hepta_Labels.csv')\n",
    "tetra = pd.read_csv('data/Tetra_Data.csv')\n",
    "tetra_labels = pd.read_csv('data/Tetra_Labels.csv')\n",
    "target = pd.read_csv('data/Target_Data.csv')\n",
    "target_labels = pd.read_csv('data/Target_Labels.csv')\n",
    "two_diamonds = pd.read_csv('data/TwoDiamonds_Data.csv')\n",
    "two_diamonds_labels = pd.read_csv('data/TwoDiamonds_Labels.csv')\n",
    "wing_nut = pd.read_csv('data/WingNut_Data.csv')\n",
    "wing_nut_labels = pd.read_csv('data/WingNut_Labels.csv')\n",
    "# Cargamos los datasets clasico de sklearn\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_labels = pd.DataFrame(iris.target, columns=['target'])\n",
    "wine_data = pd.read_csv('data/wine.csv')\n",
    "wine_labels = wine_data['good']\n",
    "wine_data = wine_data.drop(columns=['good'])\n",
    "wine_data[\"color\"] = wine_data[\"color\"].map({'red': 0, 'white': 1})\n",
    "# Cargamos los datasets de prueba de la tesis\n",
    "uniform = pd.read_csv('data/uniform_df.csv')\n",
    "uniform_data = uniform.drop(columns=['labels'])\n",
    "uniform_labels = pd.DataFrame(uniform['labels'])\n",
    "rectangle = pd.read_csv('data/rectangle_df.csv')\n",
    "rectangle_data = rectangle.drop(columns=['labels'])\n",
    "rectangle_labels = pd.DataFrame(rectangle['labels'])\n",
    "gaussian = pd.read_csv('data/gaussian_df.csv')\n",
    "gaussian_data = gaussian.drop(columns=['labels'])\n",
    "gaussian_labels = pd.DataFrame(gaussian['labels'])\n",
    "gaussian_mix = pd.read_csv('data/gaussian_mix_df.csv')\n",
    "gaussian_mix_data = gaussian_mix.drop(columns=['labels'])\n",
    "gaussian_mix_labels = pd.DataFrame(gaussian_mix['labels'])\n",
    "breast_cancer = pd.read_csv('data/breast-cancer-wisconsin.csv')\n",
    "breast_cancer = breast_cancer.drop(columns=['id'])\n",
    "breast_cancer_labels = breast_cancer['class'].map({2: 0, 4: 1})\n",
    "breast_cancer = breast_cancer.drop(columns=['class'])\n",
    "#pasar a numerico la columna bare_nucleoli\n",
    "breast_cancer['bare_nucleoli'] = pd.to_numeric(breast_cancer['bare_nucleoli'], errors='coerce')\n",
    "#dropear los nulos\n",
    "breast_cancer = breast_cancer.dropna()\n",
    "heart = pd.read_csv('data/SAheart.csv')\n",
    "heart_labels = heart['chd']\n",
    "heart = heart.drop(columns=['row.names','chd'])\n",
    "heart['famhist'] = heart['famhist'].map({'Present': 1, 'Absent': 0})\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'Atom',\n",
    "        'data': atom,\n",
    "        'labels': atom_labels,\n",
    "        'n_clusters': atom_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Chainlink',\n",
    "        'data': chainlink,\n",
    "        'labels': chainlink_labels,\n",
    "        'n_clusters': chainlink_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'EngyTime',\n",
    "        'data': engytime,\n",
    "        'labels': engytime_labels,\n",
    "        'n_clusters': engytime_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Hepta',\n",
    "        'data': hepta,\n",
    "        'labels': hepta_labels,\n",
    "        'n_clusters': hepta_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Tetra',\n",
    "        'data': tetra,\n",
    "        'labels': tetra_labels,\n",
    "        'n_clusters': tetra_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Target',\n",
    "        'data': target,\n",
    "        'labels': target_labels,\n",
    "        'n_clusters': target_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'TwoDiamonds',\n",
    "        'data': two_diamonds,\n",
    "        'labels': two_diamonds_labels,\n",
    "        'n_clusters': two_diamonds_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'WingNut',\n",
    "        'data': wing_nut,\n",
    "        'labels': wing_nut_labels,\n",
    "        'n_clusters': wing_nut_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Iris',\n",
    "        'data': iris_data,\n",
    "        'labels': iris_labels,\n",
    "        'n_clusters': 3\n",
    "    },{\n",
    "        'name': 'Wine',\n",
    "        'data': wine_data,\n",
    "        'labels': wine_labels,\n",
    "        'n_clusters': 3\n",
    "    },{\n",
    "        'name': 'Uniform',\n",
    "        'data': uniform_data,\n",
    "        'labels': uniform_labels,\n",
    "        'n_clusters': uniform_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Rectangle',\n",
    "        'data': rectangle_data,\n",
    "        'labels': rectangle_labels,\n",
    "        'n_clusters': rectangle_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'Gaussian',\n",
    "        'data': gaussian_data,\n",
    "        'labels': gaussian_labels,\n",
    "        'n_clusters': gaussian_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'GaussianMix',\n",
    "        'data': gaussian_mix_data,\n",
    "        'labels': gaussian_mix_labels,\n",
    "        'n_clusters': gaussian_mix_labels.nunique().values[0]\n",
    "    },{\n",
    "        'name': 'BreastCancer',\n",
    "        'data': breast_cancer,\n",
    "        'labels': breast_cancer_labels,\n",
    "        'n_clusters': breast_cancer_labels.nunique()\n",
    "    },{\n",
    "        'name': 'Heart',\n",
    "        'data': heart,\n",
    "        'labels': heart_labels,\n",
    "        'n_clusters': heart_labels.nunique()\n",
    "    }\n",
    "]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Atom\n",
      "Optimization started\n",
      "Processing epoch\t94\t0.0227\t\n",
      "Training time: 24.90s, epochs: 100\n",
      "\n",
      "Least training loss reached: 0.020\n",
      "Dbscan DSGD:  0.75\n",
      "Dataset: Chainlink\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0201\t\n",
      "Training time: 99.64s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.019\n",
      "Dbscan DSGD:  0.985\n",
      "Dataset: EngyTime\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0036\t\n",
      "Training time: 461.73s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.003\n",
      "Dbscan DSGD:  0.9975609756097561\n",
      "Dataset: Hepta\n",
      "Optimization started\n",
      "Processing epoch\t63\t0.0629\t\n",
      "Training time: 4.64s, epochs: 83\n",
      "\n",
      "Least training loss reached: 0.034\n",
      "Dbscan DSGD:  0.9767441860465116\n",
      "Dataset: Tetra\n",
      "Optimization started\n",
      "Processing epoch\t218\t0.0162\t\n",
      "Training time: 22.99s, epochs: 225\n",
      "\n",
      "Least training loss reached: 0.016\n",
      "Dbscan DSGD:  0.9625\n",
      "Dataset: Target\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0162\t\n",
      "Training time: 75.59s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.015\n",
      "Dbscan DSGD:  0.9935064935064936\n",
      "Dataset: TwoDiamonds\n",
      "Dataset: WingNut\n",
      "Dataset: Iris\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0593\t\n",
      "Training time: 15.50s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.059\n",
      "Dbscan DSGD:  0.8333333333333334\n",
      "Dataset: Wine\n",
      "Optimization started\n",
      "Processing epoch\t311\t0.0016\t\n",
      "Training time: 885.08s, epochs: 339\n",
      "\n",
      "Least training loss reached: 0.002\n",
      "Dbscan DSGD:  0.9692307692307692\n",
      "Dataset: Uniform\n",
      "Dataset: Rectangle\n",
      "Dataset: Gaussian\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0054\t\n",
      "Training time: 48.82s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.005\n",
      "Dbscan DSGD:  1.0\n",
      "Dataset: GaussianMix\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0057\t\n",
      "Training time: 57.25s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.005\n",
      "Dbscan DSGD:  0.9916666666666667\n",
      "Dataset: BreastCancer\n",
      "Optimization started\n",
      "Processing epoch\t373\t0.0267\t\n",
      "Training time: 66.72s, epochs: 400\n",
      "\n",
      "Least training loss reached: 0.026\n",
      "Dbscan DSGD:  0.9343065693430657\n",
      "Dataset: Heart\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n\\n    #CDSDG\\n    print(\"CDSDG\")\\n    cdsgd = DSClustering(data=data.copy())\\n    cdsgd.generate_categorical_rules()\\n    cdsgd_labels = cdsgd.predict()\\n\\n    #CDSDG mas votados\\n    print(\"CDSDG most voted\")\\n    cdsgd1 = DSClustering(data=data.copy(), most_voted=True)\\n    cdsgd1.generate_categorical_rules()\\n    cdsgd1_labels = cdsgd1.predict()\\n\\n    # CDSDG con numero de clusters\\n    print(\"CDSDG with n_clusters\")\\n    cdsgd2 = DSClustering(data=data.copy(), cluster=n_clusters)\\n    cdsgd2.generate_categorical_rules()\\n    cdsgd2_labels = cdsgd2.predict()\\n\\n    # CDSDG con numero de clusters mas votado\\n    print(\"CDSDG with n_clusters most voted\")\\n    cdsgd2 = DSClustering(data=data.copy(), cluster=n_clusters, most_voted=True)\\n    cdsgd2.generate_categorical_rules()\\n    cdsgd2_labels = cdsgd2.predict() '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iteramos sobre los datasets\n",
    "# testear al menos 10 casoss, evaluar diferencias con Ricardo\n",
    "# buscar definiciones de interpretaabilidad y como lo miden\n",
    "for dataset in datasets:\n",
    "    print(\"Dataset: \"+ dataset[\"name\"])\n",
    "    n_clusters = dataset['n_clusters']\n",
    "    data = dataset['data']\n",
    "    labels = dataset['labels'].values.ravel()\n",
    "    #normalizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data, columns=dataset['data'].columns)\n",
    "    #KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans_labels = kmeans.fit_predict(data)\n",
    "    #DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5)\n",
    "    dbscan_labels = dbscan.fit_predict(data)\n",
    "    #Agglomerative\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    agglomerative_labels = agglomerative.fit_predict(data)\n",
    "\n",
    "    #Generamos un arbol de decisión para cada metodo y calculamos su precicion\n",
    "    X_train_kmeans, X_test_kmeans, y_train_kmeans, y_test_kmeans = train_test_split(data, kmeans_labels, test_size=0.2)\n",
    "    X_train_dbscan, X_test_dbscan, y_train_dbscan, y_test_dbscan = train_test_split(data, dbscan_labels, test_size=0.2)\n",
    "    X_train_agglomerative, X_test_agglomerative, y_train_agglomerative, y_test_agglomerative = train_test_split(data, agglomerative_labels, test_size=0.2)    \n",
    "    X_train_kmeans = X_train_kmeans.to_numpy()\n",
    "    X_test_kmeans = X_test_kmeans.to_numpy()\n",
    "    X_train_dbscan = X_train_dbscan.to_numpy()\n",
    "    X_test_dbscan = X_test_dbscan.to_numpy()\n",
    "    X_train_agglomerative = X_train_agglomerative.to_numpy()\n",
    "    X_test_agglomerative = X_test_agglomerative.to_numpy()\n",
    "    #DSGD\n",
    "    \"\"\"     dsgd = DSClassifierMultiQ(num_classes=n_clusters, min_iter=50, max_iter=400, debug_mode=True, \\\n",
    "                            lossfn=\"MSE\", num_workers=0, min_dloss=1e-7)\n",
    "        dsgd.fit(X_train_kmeans,y_train_kmeans, add_single_rules=True, single_rules_breaks=3,\n",
    "                                    column_names=data.columns[:], print_every_epochs=31)\n",
    "        print(\"Kmeans DSGD: \", accuracy_score(y_test_kmeans, dsgd.predict(X_test_kmeans)))\n",
    "        results.append({\n",
    "            'dataset': dataset['name'],\n",
    "            \"algorithm\": \"Kmeans DSGD\",\n",
    "            \"accuracy\": accuracy_score(y_test_kmeans, dsgd.predict(X_test_kmeans))\n",
    "        }) \"\"\"\n",
    "    #debe existir mas de 1 cluster y todos los labels deben ser positivos\n",
    "    if np.unique(dbscan_labels).shape[0] > 1 and np.all(dbscan_labels >= 0):\n",
    "        dsgd = DSClassifierMultiQ(num_classes=np.unique(dbscan_labels).shape[0], min_iter=50, max_iter=400, debug_mode=True, \\\n",
    "                         lossfn=\"MSE\", num_workers=0, min_dloss=1e-7)\n",
    "        dsgd.fit(X_train_dbscan, y_train_dbscan, add_single_rules=True,\n",
    "                            single_rules_breaks=3, add_mult_rules=False,\n",
    "                                column_names=data.columns[:], print_every_epochs=31)\n",
    "        print(\"Dbscan DSGD: \", accuracy_score(y_test_dbscan, dsgd.predict(X_test_dbscan)))\n",
    "        results.append({\n",
    "            'dataset': dataset['name'],\n",
    "            \"algorithm\": \"Dbscan DSGD\",\n",
    "            \"accuracy\": accuracy_score(y_test_dbscan, dsgd.predict(X_test_dbscan))\n",
    "        })\n",
    "    elif np.unique(dbscan_labels).shape[0] > 1:\n",
    "        # print different labels\n",
    "        y_train_dbscan = np.where(y_train_dbscan == -1, len(np.unique(dbscan_labels)) - 1, y_train_dbscan)\n",
    "        y_test_dbscan = np.where(y_test_dbscan == -1, len(np.unique(dbscan_labels)) - 1, y_test_dbscan)\n",
    "        dsgd = DSClassifierMultiQ(num_classes=np.unique(dbscan_labels).shape[0], min_iter=50, max_iter=400, debug_mode=True, \\\n",
    "                         lossfn=\"MSE\", num_workers=0, min_dloss=1e-7)\n",
    "        dsgd.fit(X_train_dbscan, y_train_dbscan, add_single_rules=True,\n",
    "                            single_rules_breaks=3, add_mult_rules=False,\n",
    "                                column_names=data.columns[:], print_every_epochs=31)\n",
    "        print(\"Dbscan DSGD: \", accuracy_score(y_test_dbscan, dsgd.predict(X_test_dbscan)))\n",
    "        results.append({\n",
    "            'dataset': dataset['name'],\n",
    "            \"algorithm\": \"Dbscan DSGD\",\n",
    "            \"accuracy\": accuracy_score(y_test_dbscan, dsgd.predict(X_test_dbscan))\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            'dataset': dataset['name'],\n",
    "            \"algorithm\": \"Dbscan DSGD\",\n",
    "            \"accuracy\": 0\n",
    "        })\n",
    "    \n",
    "    \"\"\"     dsgd = DSClassifierMultiQ(num_classes=n_clusters, min_iter=50, max_iter=400, debug_mode=True, \\\n",
    "                            lossfn=\"MSE\", num_workers=0, min_dloss=1e-7)\n",
    "        dsgd.fit(X=X_train_agglomerative, y=y_train_agglomerative, add_single_rules=True,\n",
    "                                single_rules_breaks=3, add_mult_rules=False,\n",
    "                                    column_names=data.columns[:], print_every_epochs=31)\n",
    "        print(\"Agglomerative DSGD: \", accuracy_score(y_test_agglomerative, dsgd.predict(X_test_agglomerative)))\n",
    "        results.append({\n",
    "            'dataset': dataset['name'],\n",
    "            \"algorithm\": \"Agglomerative DSGD\",\n",
    "            \"accuracy\": accuracy_score(y_test_agglomerative, dsgd.predict(X_test_agglomerative))\n",
    "        }) \"\"\"\n",
    "    \n",
    "    \"\"\" dt_kmeans = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_kmeans.fit(X_train_kmeans, y_train_kmeans)\n",
    "    print(\"Kmeans Dt: \", accuracy_score(y_test_kmeans, dt_kmeans.predict(X_test_kmeans)))\n",
    "    dt_dbscan = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_dbscan.fit(X_train_dbscan, y_train_dbscan)\n",
    "    print(\"Dbscan Dt: \", accuracy_score(y_test_dbscan, dt_dbscan.predict(X_test_dbscan)))\n",
    "    dt_agglomerative = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_agglomerative.fit(X_train_agglomerative, y_train_agglomerative)\n",
    "    print(\"Agglomerative Dt: \", accuracy_score(y_test_agglomerative, dt_agglomerative.predict(X_test_agglomerative)))   \n",
    "     \"\"\"\n",
    "    \"\"\" #Ripper accuracy\n",
    "    kmeans_lw_accuracy = []\n",
    "    for i in range(np.unique(kmeans_labels).shape[0]):\n",
    "        kmeans_labels_pos = (kmeans_labels == i).astype(int)\n",
    "        ripper = lw.RIPPER()\n",
    "        df = pd.concat([data, pd.DataFrame(kmeans_labels_pos, columns=['cluster'])], axis=1)\n",
    "        ripper.fit(df, class_feat=\"cluster\", pos_class=1)\n",
    "        kmeans_lw_accuracy.append(accuracy_score(kmeans_labels_pos, ripper.predict(df)))\n",
    "    print(\"Kmeans Ripper: \", np.mean(kmeans_lw_accuracy))\n",
    "    dbscan_lw_accuracy = []\n",
    "    for i in range(np.unique(dbscan_labels).shape[0]):\n",
    "        dbscan_labels_pos = (dbscan_labels == i).astype(int)\n",
    "        ripper = lw.RIPPER()\n",
    "        df = pd.concat([data, pd.DataFrame(dbscan_labels_pos, columns=['cluster'])], axis=1)\n",
    "        ripper.fit(df, class_feat=\"cluster\", pos_class=1)\n",
    "        dbscan_lw_accuracy.append(accuracy_score(dbscan_labels_pos, ripper.predict(df)))\n",
    "    print(\"Dbscan Ripper: \", np.mean(dbscan_lw_accuracy))\n",
    "    agglomerative_lw_accuracy = []\n",
    "    for i in range(np.unique(agglomerative_labels).shape[0]):\n",
    "        agglomerative_labels_pos = (agglomerative_labels == i).astype(int)\n",
    "        ripper = lw.RIPPER()\n",
    "        df = pd.concat([data, pd.DataFrame(agglomerative_labels_pos, columns=['cluster'])], axis=1)\n",
    "        ripper.fit(df, class_feat=\"cluster\", pos_class=1)\n",
    "        agglomerative_lw_accuracy.append(accuracy_score(agglomerative_labels_pos, ripper.predict(df)))\n",
    "    print(\"Agglomerative Ripper: \", np.mean(agglomerative_lw_accuracy)) \"\"\"\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "    #CDSDG\n",
    "    print(\"CDSDG\")\n",
    "    cdsgd = DSClustering(data=data.copy())\n",
    "    cdsgd.generate_categorical_rules()\n",
    "    cdsgd_labels = cdsgd.predict()\n",
    "\n",
    "    #CDSDG mas votados\n",
    "    print(\"CDSDG most voted\")\n",
    "    cdsgd1 = DSClustering(data=data.copy(), most_voted=True)\n",
    "    cdsgd1.generate_categorical_rules()\n",
    "    cdsgd1_labels = cdsgd1.predict()\n",
    "\n",
    "    # CDSDG con numero de clusters\n",
    "    print(\"CDSDG with n_clusters\")\n",
    "    cdsgd2 = DSClustering(data=data.copy(), cluster=n_clusters)\n",
    "    cdsgd2.generate_categorical_rules()\n",
    "    cdsgd2_labels = cdsgd2.predict()\n",
    "\n",
    "    # CDSDG con numero de clusters mas votado\n",
    "    print(\"CDSDG with n_clusters most voted\")\n",
    "    cdsgd2 = DSClustering(data=data.copy(), cluster=n_clusters, most_voted=True)\n",
    "    cdsgd2.generate_categorical_rules()\n",
    "    cdsgd2_labels = cdsgd2.predict() \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
